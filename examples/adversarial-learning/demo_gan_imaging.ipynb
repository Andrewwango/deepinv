{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imaging inverse problems with adversarial networks\n",
    "\n",
    "This example shows you how to train various networks using adversarial training for deblurring problems. We demonstrate running training and inference using a conditional GAN (i.e DeblurGAN), CSGM, AmbientGAN and UAIR implemented in the `deepinv` library, and how to simply train your own GAN by using `deepinv.training.AdversarialTrainer`. These examples can also be easily extended to train more complicated GANs such as CycleGAN.\n",
    "\n",
    "- Kupyn et al., [_DeblurGAN: Blind Motion Deblurring Using Conditional Adversarial Networks_](https://openaccess.thecvf.com/content_cvpr_2018/papers/Kupyn_DeblurGAN_Blind_Motion_CVPR_2018_paper.pdf)\n",
    "- Bora et al., [_Compressed Sensing using Generative Models_](https://arxiv.org/abs/1703.03208) (CSGM)\n",
    "- Bora et al., [_AmbientGAN: Generative models from lossy measurements_](https://openreview.net/forum?id=Hy7fDog0b)\n",
    "- Pajot et al., [_Unsupervised Adversarial Image Reconstruction_](https://openreview.net/forum?id=BJg4Z3RqF7)\n",
    "\n",
    "Adversarial networks are characterised by the addition of an adversarial loss $\\mathcal{L}_\\text{adv}$ to the standard reconstruction loss:\n",
    "\n",
    "$$\\mathcal{L}_\\text{adv}(x,\\hat x;D)=\\mathbb{E}_{x\\sim p_x}\\left[q(D(x))\\right]+\\mathbb{E}_{\\hat x\\sim p_{\\hat x}}\\left[q(1-D(\\hat x))\\right]$$\n",
    "\n",
    "where $D(\\cdot)$ is the discriminator model, $x$ is the reference image, $\\hat x$ is the estimated reconstruction, $q(\\cdot)$ is a quality function (e.g $q(x)=x$ for WGAN). Training alternates between generator $f$ and discriminator $D$ in a minimax game. When there are no ground truths (i.e unsupervised), this may be defined on the measurements $y$ instead.\n",
    "\n",
    "**Conditional GAN** forward pass: \n",
    "\n",
    "$$\\hat x = f(y)$$\n",
    "\n",
    "**Conditional GAN** loss: \n",
    "\n",
    "$$\\mathcal{L}=\\mathcal{L}_\\text{sup}(\\hat x, x)+\\mathcal{L}_\\text{adv}(\\hat x, x;D)$$\n",
    "\n",
    "where $\\mathcal{L}_\\text{sup}$ is a supervised loss such as pixel-wise MSE or VGG Perceptual Loss.\n",
    "\n",
    "**CSGM**/**AmbientGAN** forward pass: \n",
    "\n",
    "$$\\hat x = f(z),\\quad z\\sim \\mathcal{N}(\\mathbf{0},\\mathbf{I}_k)$$\n",
    "\n",
    "**CSGM** loss:\n",
    "\n",
    "$$\\mathcal{L}=\\mathcal{L}_\\text{adv}(\\hat x, x;D)$$\n",
    "\n",
    "**AmbientGAN** loss (where $A(\\cdot)$ is the physics): \n",
    "\n",
    "$$\\mathcal{L}=\\mathcal{L}_\\text{adv}(A(\\hat x), y;D)$$\n",
    "\n",
    "**CSGM**/**AmbientGAN** forward pass at eval time:\n",
    "\n",
    "$$\\hat x = f(\\hat z)\\quad\\text{s.t.}\\quad\\hat z=\\operatorname*{argmin}_z \\lVert A(f(z))-y\\rVert _2^2$$\n",
    "\n",
    "**UAIR** forward pass:\n",
    "\n",
    "$$\\hat x = f(y)$$\n",
    "\n",
    "**UAIR** loss: \n",
    "\n",
    "$$\\mathcal{L}=\\mathcal{L}_\\text{adv}(\\hat y, y;D)+\\lVert A(f(\\hat y))- \\hat y\\rVert^2_2,\\quad\\hat y=A(\\hat x)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import deepinv as dinv\n",
    "from deepinv.loss import adversarial\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import Compose, ToTensor, CenterCrop\n",
    "from torchvision.datasets.utils import download_and_extract_archive\n",
    "\n",
    "device = dinv.utils.get_freer_gpu() if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data and apply some forward degradation to the images. For this example we use the Urban100 dataset resized to 64x64. For simplicity we apply an isotropic Gaussian blur for demonstration, although the original papers deal with inverse problems with unknown blurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "physics = dinv.physics.Blur(dinv.physics.blur.gaussian_blur(sigma=(5, 5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: Urban100\\Urban100_HR.tar.gz\n",
      "Extracting Urban100\\Urban100_HR.tar.gz to Urban100\n"
     ]
    }
   ],
   "source": [
    "download_and_extract_archive(\n",
    "    \"https://huggingface.co/datasets/eugenesiow/Urban100/resolve/main/data/Urban100_HR.tar.gz?download=true\",\n",
    "    \"Urban100\",\n",
    "    filename=\"Urban100_HR.tar.gz\",\n",
    "    md5=\"65d9d84a34b72c6f7ca1e26a12df1e4c\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing train measurement vectors from base dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:03<00:00,  1.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing test measurement vectors from base dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 10.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset has been saved in Urban100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_dataset, test_dataset = random_split(ImageFolder(\"Urban100\", transform=Compose([ToTensor(), CenterCrop(64)])), (0.8, 0.2))\n",
    "\n",
    "dataset_path = dinv.datasets.generate_dataset(\n",
    "    train_dataset= train_dataset,\n",
    "    test_dataset = test_dataset,\n",
    "    physics=physics,\n",
    "    device=device,\n",
    "    save_dir=f\"Urban100\",\n",
    "    )\n",
    "    \n",
    "train_dataloader = DataLoader(\n",
    "    dinv.datasets.HDF5Dataset(dataset_path, train=True), \n",
    "    shuffle=True\n",
    ")\n",
    "test_dataloader = DataLoader(\n",
    "    dinv.datasets.HDF5Dataset(dataset_path, train=False),\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define reconstruction network (i.e conditional generator) and discriminator network to use for adversarial training. For demonstration we use a simple U-Net as the reconstruction network and the discriminator from [PatchGAN](https://arxiv.org/abs/1611.07004), but these can be replaced with any architecture e.g transformers, unrolled etc. Further discriminator models are in `deepinv.models.gan`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_models(model=None, D=None, lr_g=1e-4, lr_d=1e-4):\n",
    "    if model is None:\n",
    "        model = dinv.models.UNet(\n",
    "            in_channels=3, \n",
    "            out_channels=3,\n",
    "            scales=2,\n",
    "            circular_padding=True,\n",
    "            batch_norm=False\n",
    "            )\n",
    "\n",
    "    if D is None:\n",
    "        D = dinv.models.PatchGANDiscriminator(\n",
    "            n_layers=2,\n",
    "            batch_norm=False\n",
    "        )\n",
    "\n",
    "    optimizer = dinv.training.adversarial.AdversarialOptimizer(\n",
    "        torch.optim.Adam(model.parameters(), lr=lr_g, weight_decay=1e-8),\n",
    "        torch.optim.Adam(D.parameters(),     lr=lr_d, weight_decay=1e-8),\n",
    "    )\n",
    "    scheduler = dinv.training.adversarial.AdversarialScheduler(\n",
    "        torch.optim.lr_scheduler.StepLR(optimizer.G, step_size=5, gamma=0.9),\n",
    "        torch.optim.lr_scheduler.StepLR(optimizer.D, step_size=5, gamma=0.9)\n",
    "    )\n",
    "    \n",
    "    return model, D, optimizer, scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conditional GAN training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, D, optimizer, scheduler = get_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct pixel-wise and adversarial losses as defined above. We use the MSE for the supervised pixel-wise metric for simplicity but this can be easily replaced with a perceptual loss if desired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_g = [\n",
    "    dinv.loss.SupLoss(metric=torch.nn.MSELoss()),\n",
    "    adversarial.SupAdversarialGeneratorLoss(device=device)\n",
    "]\n",
    "loss_d = adversarial.SupAdversarialDiscriminatorLoss(device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the networks using `AdversarialTrainer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 444867 trainable parameters\n",
      "Eval epoch 0: PSNR=14.884\n",
      "Train epoch 0: SupLoss=0.023 SupAdversarialGeneratorLoss=0.004 TotalLoss=1.0 PSNR=17.141\n",
      "Eval epoch 1: PSNR=17.094\n",
      "Train epoch 1: SupLoss=0.022 SupAdversarialGeneratorLoss=0.004 TotalLoss=1.0 PSNR=17.635\n",
      "Eval epoch 2: PSNR=17.57\n",
      "Train epoch 2: SupLoss=0.022 SupAdversarialGeneratorLoss=0.004 TotalLoss=1.0 PSNR=17.787\n"
     ]
    }
   ],
   "source": [
    "model = dinv.training.AdversarialTrainer(\n",
    "    model=model,\n",
    "    D=D,\n",
    "    physics=physics,\n",
    "    train_dataloader=train_dataloader,\n",
    "    eval_dataloader=test_dataloader,\n",
    "    epochs=3,\n",
    "    losses=loss_g,\n",
    "    losses_d=loss_d,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    verbose=True,\n",
    "    progress_bar=False,\n",
    "    save_path=None,\n",
    "    device=device\n",
    ").train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UAIR training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, D, optimizer, scheduler = get_models(lr_g=1e-4, lr_d=4e-4) # learning rates from original paper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct losses as defined above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_g = adversarial.UAIRGeneratorLoss(device=device)\n",
    "loss_d = adversarial.UAIRDiscriminatorLoss(device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the networks using `AdversarialTrainer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 444867 trainable parameters\n",
      "Eval epoch 0: PSNR=15.679\n",
      "Train epoch 0: TotalLoss=1.0 PSNR=16.242\n",
      "Eval epoch 1: PSNR=15.989\n",
      "Train epoch 1: TotalLoss=1.0 PSNR=16.176\n",
      "Eval epoch 2: PSNR=16.112\n",
      "Train epoch 2: TotalLoss=1.0 PSNR=16.158\n"
     ]
    }
   ],
   "source": [
    "model = dinv.training.AdversarialTrainer(\n",
    "    model=model,\n",
    "    D=D,\n",
    "    physics=physics,\n",
    "    train_dataloader=train_dataloader,\n",
    "    eval_dataloader=test_dataloader,\n",
    "    epochs=3,\n",
    "    losses=loss_g,\n",
    "    losses_d=loss_d,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    verbose=True,\n",
    "    progress_bar=False,\n",
    "    save_path=None,\n",
    "    device=device\n",
    ").train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CSGM / AmbientGAN training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = dinv.models.CSGMGenerator(dinv.models.DCGANGenerator(nz=100, ngf=32), inf_tol=1e-2)\n",
    "D = dinv.models.DCGANDiscriminator(ndf=32)\n",
    "_, _, optimizer, scheduler = get_models(model=model, D=D, lr_g=2e-4, lr_d=2e-4) # learning rates from original paper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct losses as defined above. We are free to choose between supervised and unsupervised adversarial losses, where supervised gives CSGM and unsupervised gives AmbientGAN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_g = adversarial.SupAdversarialGeneratorLoss(device=device)\n",
    "loss_d = adversarial.SupAdversarialDiscriminatorLoss(device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the networks using `AdversarialTrainer`. Since inference is very slow for CSGM/AmbientGAN as it requires an optimisation, we only do one evaluation at the end. Note the train PSNR is meaningless as this generative model is trained on random latents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 1100224 trainable parameters\n",
      "Train epoch 0: TotalLoss=1.0 PSNR=2.244\n",
      "Train epoch 1: TotalLoss=1.0 PSNR=2.672\n",
      "Train epoch 2: TotalLoss=1.0 PSNR=2.942\n"
     ]
    }
   ],
   "source": [
    "trainer = dinv.training.AdversarialTrainer(\n",
    "    model=model,\n",
    "    D=D,\n",
    "    physics=physics,\n",
    "    train_dataloader=train_dataloader,\n",
    "    epochs=3,\n",
    "    losses=loss_g,\n",
    "    losses_d=loss_d,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    verbose=True,\n",
    "    progress_bar=False,\n",
    "    save_path=None,\n",
    "    device=device\n",
    ")\n",
    "model = trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run evaluation of generative model by running test-time optimisation using test measurements. Note that we do not get great results as CSGM / AmbientGAN relies on large datasets of diverse samples, and we run the optimisation to a relatively high tolerance for speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test PSNR: No learning rec.: 15.945+-2.634 | Model: 3.521+-0.816. \n",
      "Test PSNR 3.521284806728363\n"
     ]
    }
   ],
   "source": [
    "psnr = trainer.test(test_dataloader)[0]\n",
    "print(\"Test PSNR\", psnr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
