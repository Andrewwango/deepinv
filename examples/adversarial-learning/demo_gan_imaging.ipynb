{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imaging inverse problems with adversarial networks\n",
    "\n",
    "This example shows you how to train various networks using adversarial training for deblurring problems. We demonstrate running training and inference using DeblurGAN, AmbientGAN and UAIR implemented in the `deepinv` library, and how to simply train your own GAN by using `deepinv.training.AdversarialTrainer`. These examples can also be easily extended to train more complicated GANs such as CycleGAN.\n",
    "\n",
    "- Kupyn et al., [_DeblurGAN: Blind Motion Deblurring Using Conditional Adversarial Networks_](https://openaccess.thecvf.com/content_cvpr_2018/papers/Kupyn_DeblurGAN_Blind_Motion_CVPR_2018_paper.pdf)\n",
    "- Bora et al., [_AmbientGAN: Generative models from lossy measurements_](https://openreview.net/forum?id=Hy7fDog0b)\n",
    "- Pajot et al., [_Unsupervised Adversarial Image Reconstruction_](https://openreview.net/forum?id=BJg4Z3RqF7)\n",
    "\n",
    "Adversarial networks are characterised by the addition of an adversarial loss $\\mathcal{L}_\\text{adv}$ to the standard reconstruction loss:\n",
    "\n",
    "$$\\mathcal{L}_\\text{adv}(x,\\hat x;D)=\\mathbb{E}_{x\\sim p_x}\\left[q(D(x))\\right]+\\mathbb{E}_{\\hat x\\sim p_{\\hat x}}\\left[q(1-D(\\hat x))\\right]$$\n",
    "\n",
    "where $D(\\cdot)$ is the discriminator model, $x$ is the reference image, $\\hat x$ is the estimated reconstruction, $q(\\cdot)$ is a quality function (e.g $q(x)=x$ for WGAN). Training alternates between generator $f$ and discriminator $D$ in a minimax game. When there are no ground truths (i.e unsupervised), this may be defined on the measurements $y$ instead.\n",
    "\n",
    "**DeblurGAN** forward pass: \n",
    "\n",
    "$$\\hat x = f(y)$$\n",
    "\n",
    "**DeblurGAN** loss: \n",
    "\n",
    "$$\\mathcal{L}=\\mathcal{L}_\\text{sup}(\\hat x, x)+\\mathcal{L}_\\text{adv}(\\hat x, x;D)$$\n",
    "\n",
    "where $\\mathcal{L}_\\text{sup}$ is a supervised loss such as pixel-wise MSE or VGG Perceptual Loss.\n",
    "\n",
    "**AmbientGAN** forward pass: \n",
    "\n",
    "$$\\hat x = f(z),\\quad z\\sim \\mathcal{N}(\\mathbf{0},\\mathbf{I}_k)$$\n",
    "\n",
    "**AmbientGAN** loss (where $A(\\cdot)$ is the physics): \n",
    "\n",
    "$$\\mathcal{L}=\\mathcal{L}_\\text{adv}(A(\\hat x), y;D)$$\n",
    "\n",
    "Forward pass at eval time:\n",
    "\n",
    "$$\\hat x = f(\\hat z)\\quad\\text{s.t.}\\quad\\hat z=\\operatorname*{argmin}_z D(A(f(z)),y)$$\n",
    "\n",
    "**UAIR** forward pass:\n",
    "\n",
    "$$\\hat x = f(y)$$\n",
    "\n",
    "**UAIR** loss: \n",
    "\n",
    "$$\\mathcal{L}=\\mathcal{L}_\\text{adv}(\\hat y, y;D)+\\lVert A(f(\\hat y))- \\hat y\\rVert^2_2,\\quad\\hat y=A(\\hat x)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import deepinv as dinv\n",
    "from deepinv.loss import adversarial\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import Compose, ToTensor, CenterCrop\n",
    "from torchvision.datasets.utils import download_and_extract_archive\n",
    "\n",
    "device = dinv.utils.get_freer_gpu() if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data and apply some forward degradation to the images. For this example we use the Urban100 dataset resized to 128x128. For simplicity we apply an isotropic Gaussian blur for demonstration, although the original papers deal with harder inverse problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "physics = dinv.physics.Blur(dinv.physics.blur.gaussian_blur(sigma=(5, 5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://cdn-lfs.huggingface.co/datasets/eugenesiow/Urban100/25b929945e053de19bf8f575bd0821abab1eac7f5f6c5c7980221d8ed13066c6?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27Urban100_HR.tar.gz%3B+filename%3D%22Urban100_HR.tar.gz%22%3B&response-content-type=application%2Fgzip&Expires=1712826916&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcxMjgyNjkxNn19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9kYXRhc2V0cy9ldWdlbmVzaW93L1VyYmFuMTAwLzI1YjkyOTk0NWUwNTNkZTE5YmY4ZjU3NWJkMDgyMWFiYWIxZWFjN2Y1ZjZjNWM3OTgwMjIxZDhlZDEzMDY2YzY%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qJnJlc3BvbnNlLWNvbnRlbnQtdHlwZT0qIn1dfQ__&Signature=ZFgKEmpyl3OBXB2YDrKDV1miFt55U2EzW-3jhGnPZEbFDwio7ptL%7EgKqX7uH9lbO5Q9ZjBUUw9UJfOKzMkp9tbiwzSXs910OwVRaFhR15tpDFxZn9dAWK4cGKtEjRaEeacQgVKBBVSzX1jf0BUHOGnnhL8BfNFsNSUHW-poogSN7-rVQVYROzIdeDOfSe6UhSLiAEYTYpG76UcTf%7E-s37Aiu0FwT1oszx6WnlGP8z09WmtaXMlvx21el24Jtj5wmx5-qKOIZSXYX1BEsVIynMcoDSqCq2pfdhVTIaDMpLpenLcpwmdzjlsseQLIvw6s85GB7zywRGGyKfJ9wz-2T%7EA__&Key-Pair-Id=KVTP0A1DKRTAX to Urban100\\Urban100_HR.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 135388067/135388067 [00:10<00:00, 12587619.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting Urban100\\Urban100_HR.tar.gz to Urban100\n"
     ]
    }
   ],
   "source": [
    "download_and_extract_archive(\n",
    "            \"https://huggingface.co/datasets/eugenesiow/Urban100/resolve/main/data/Urban100_HR.tar.gz?download=true\",\n",
    "            \"Urban100\",\n",
    "            filename=\"Urban100_HR.tar.gz\",\n",
    "            md5=\"65d9d84a34b72c6f7ca1e26a12df1e4c\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing train measurement vectors from base dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:04<00:00,  2.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing test measurement vectors from base dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00,  9.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset has been saved in Urban100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_dataset, test_dataset = random_split(ImageFolder(\"Urban100\", transform=Compose([ToTensor(), CenterCrop(128)])), (0.8, 0.2))\n",
    "\n",
    "dataset_path = dinv.datasets.generate_dataset(\n",
    "    train_dataset= train_dataset,\n",
    "    test_dataset = test_dataset,\n",
    "    physics=physics,\n",
    "    device=device,\n",
    "    save_dir=f\"Urban100\",\n",
    "    )\n",
    "    \n",
    "train_dataloader = DataLoader(\n",
    "    dinv.datasets.HDF5Dataset(dataset_path, train=True), \n",
    "    shuffle=True\n",
    ")\n",
    "test_dataloader = DataLoader(\n",
    "    dinv.datasets.HDF5Dataset(dataset_path, train=False),\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define reconstruction network (i.e. conditional generator) and discriminator network to use for adversarial training. For demonstration we use a simple U-Net as the reconstruction network and the discriminator from [PatchGAN](https://arxiv.org/abs/1611.07004), but these can be replaced with any architecture e.g. transformers, unrolled etc. Further discriminator models are in `deepinv.models.gan`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_models(lr_g=1e-4, lr_d=1e-4):\n",
    "    model = dinv.models.UNet(\n",
    "        in_channels=3, \n",
    "        out_channels=3,\n",
    "        scales=2,\n",
    "        circular_padding=True,\n",
    "        batch_norm=False\n",
    "        )\n",
    "\n",
    "    D = dinv.models.PatchGANDiscriminator(\n",
    "        n_layers=2,\n",
    "        batch_norm=False\n",
    "    )\n",
    "\n",
    "    #TODO make sure zero_grad_only right way round for training\n",
    "    optimizer = dinv.training.adversarial_training.AdversarialOptimizer(\n",
    "        torch.optim.Adam(model.parameters(), lr=lr_g, weight_decay=1e-8),\n",
    "        torch.optim.Adam(D.parameters(),     lr=lr_d, weight_decay=1e-8),\n",
    "    )\n",
    "    scheduler = dinv.training.adversarial_training.AdversarialScheduler(\n",
    "        torch.optim.lr_scheduler.StepLR(optimizer.G, step_size=5, gamma=0.9),\n",
    "        torch.optim.lr_scheduler.StepLR(optimizer.D, step_size=5, gamma=0.9)\n",
    "    )\n",
    "    \n",
    "    return model, D, optimizer, scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DeblurGAN training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, D, optimizer, scheduler = get_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct pixel-wise and adversarial losses as defined above. We use the MSE for the supervised pixel-wise metric for simplicity but this can be easily replaced with a perceptual loss if desired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_g = [\n",
    "    dinv.loss.SupLoss(metric=torch.nn.MSELoss),\n",
    "    adversarial.DeblurGANGeneratorLoss()\n",
    "]\n",
    "loss_d = adversarial.DeblurGANDiscriminatorLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the networks using `AdversarialTrainer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dinv.training.adversarial_training.AdversarialTrainer(\n",
    "    D=D,\n",
    "    epochs=5,\n",
    "    losses=loss_g,\n",
    "    losses_d=loss_d,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    device=device,\n",
    "    verbose=True\n",
    ").train(\n",
    "    model=model,\n",
    "    physics=physics,\n",
    "    train_dataloader=train_dataloader,\n",
    "    eval_dataloader=test_dataloader\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UAIR training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, D, optimizer, scheduler = get_models(lr_g=1e-4, lr_d=4e-4) # learning rates from original paper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct losses as defined above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_g = adversarial.UAIRGeneratorLoss()\n",
    "loss_d = adversarial.UAIRDiscriminatorLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the networks using `AdversarialTrainer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dinv.training.adversarial_training.AdversarialTrainer(\n",
    "    D=D,\n",
    "    epochs=5,\n",
    "    losses=loss_g,\n",
    "    losses_d=loss_d,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    device=device,\n",
    "    verbose=True\n",
    ").train(\n",
    "    model=model,\n",
    "    physics=physics,\n",
    "    train_dataloader=train_dataloader,\n",
    "    eval_dataloader=test_dataloader\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AmbientGAN training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, D, optimizer, scheduler = get_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO wrap model so that it produces outputs from random inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct losses as defined above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO weights\n",
    "loss_g = adversarial.AmbientGANGeneratorLoss(...)\n",
    "loss_d = adversarial.AmbientGANDiscriminatorLoss(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the networks using `AdversarialTrainer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dinv.training.adversarial_training.AdversarialTrainer(\n",
    "    D=D,\n",
    "    epochs=5,\n",
    "    losses=loss_g,\n",
    "    losses_d=loss_d,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    device=device,\n",
    "    verbose=True\n",
    ").train(\n",
    "    model=model,\n",
    "    physics=physics,\n",
    "    train_dataloader=train_dataloader,\n",
    "    eval_dataloader=test_dataloader\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
